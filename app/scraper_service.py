"""
BookingScraper/app/scraper_service.py  v4.0  [ENGLISH ENFORCEMENT + LANG MISMATCH BLOCK]
Servicio de scraping directo - BookingScraper Pro

CAMBIOS v4.0 [FIX CR√çTICO - BLOQUEAR GUARDADO EN IDIOMA INCORRECTO]:

  DIAGN√ìSTICO CONFIRMADO (CSV exportado de BD):
  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚óè url_id=322 lang=en (id=637): rating_category='Exceptional' (‚úì ingl√©s)
    PERO description/services/facilities/house_rules ‚Üí TODO EN ESPA√ëOL ‚úó
    CAUSA: scraper_service.py v3.1 detectaba mismatch pero GUARDABA igualmente.
    L√≠nea 380-404 v3.1: "loguear advertencia pero guardar igualmente (el
    contenido puede ser √∫til aunque est√© en idioma incorrecto)". ‚Üê INCORRECTO.

  ‚óè url_id=321/323/324: sin registro EN. El ingl√©s nunca se guard√≥.

  ‚óè url_id=323 lang=it+es: descripci√≥n en INGL√âS guardada bajo idioma incorrecto.
    El extractor recibi√≥ p√°gina inglesa pero el service la guard√≥ como 'it'/'es'
    porque el detected_lang check era warning-only, no bloqueante.

  [FIX #20 - CR√çTICO] Mismatch de idioma ‚Üí NO GUARDAR, loguear como 'lang_mismatch'
    ANTES v3.1: detected_lang != lang ‚Üí warning + guardar dato incorrecto
    AHORA v4.0: detected_lang != lang ‚Üí ERROR + skip save + log status='lang_mismatch'
    El dato en idioma incorrecto NO entra en BD bajo ninguna circunstancia.

  [FIX #21] Im√°genes: solo descargar cuando lang='en' Y detected_lang='en'
    ANTES v3.1: primer idioma exitoso (pod√≠a ser 'es' con contenido ES)
    AHORA v4.0: solo si lang == DEFAULT ('en') y la p√°gina est√° confirmada en ingl√©s
    Carpeta destino hardcodeada a 'en' independientemente del idioma detectado.
    Esto garantiza que images/hotel_X/en/ existe y contiene im√°genes correctas.

  [FIX #22] Retry en mismatch de idioma (solo para lang='en')
    Cuando Booking.com devuelve espa√±ol para una URL en ingl√©s, el service
    reintenta hasta MAX_LANG_RETRY=2 veces adicionales con nueva sesi√≥n/CloudScraper.
    Si tras los reintentos sigue siendo espa√±ol ‚Üí lang_mismatch definitivo.
    Los otros idiomas (de/fr/it/es) no reintentan (son menos cr√≠ticos).

  [FIX #23] Estad√≠sticas: nuevo campo 'lang_mismatch_blocked' (datos rechazados)
    diferenciado de 'lang_mismatch_count' (contador para rotaci√≥n VPN).

CAMBIOS v3.1: im√°genes del primer idioma exitoso + images_count fix + mismatch warning.
CAMBIOS v3.0: VPN US-first + American English (en-us).
CAMBIOS v2.x: mejoras incrementales (ver historial git).
"""

import json
import time
import threading
from concurrent.futures import ThreadPoolExecutor
from typing import Dict, List, Optional, Set
from loguru import logger

from sqlalchemy import text

from app.database import SessionLocal
from app.config import settings


# ‚îÄ‚îÄ POOL DE THREADS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# [FIX v2.3] max_workers=1: UN hotel a la vez elimina toda la contenci√≥n de VPN,
#            DB pool y DNS. Aumentar a 2-3 solo cuando el sistema sea estable.
_executor = ThreadPoolExecutor(
    max_workers=1,
    thread_name_prefix="scraper"
)

# Conjunto de IDs actualmente en proceso
_lock = threading.Lock()
_active_ids: Set[int] = set()

# Contador global de estado
_stats = {
    "total_dispatched": 0,
    "total_completed": 0,
    "total_failed": 0,
    "currently_processing": 0,
    "consecutive_failures": 0,    # detecta bloqueo IP
    "hotels_since_vpn_rotate": 0, # contador para rotaci√≥n peri√≥dica VPN
    "lang_mismatch_count": 0,     # mismatches de idioma consecutivos ‚Üí rota VPN al llegar a 3
    "lang_mismatch_blocked": 0,   # [v4.0] registros rechazados por idioma incorrecto (no guardados)
}

# [v4.0] M√°ximo de reintentos cuando Booking.com devuelve idioma incorrecto para 'en'
_MAX_LANG_RETRY = 2
_stats_lock = threading.Lock()


# ‚îÄ‚îÄ VPN MANAGER SINGLETON ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Se inicializa una sola vez y se comparte entre todos los threads del scraper
_vpn_manager = None
_vpn_lock = threading.Lock()


def _get_vpn_manager():
    """
    Devuelve el VPN manager singleton (thread-safe).
    Solo se inicializa si VPN_ENABLED=True en .env
    """
    global _vpn_manager
    if not settings.VPN_ENABLED:
        return None

    with _vpn_lock:
        if _vpn_manager is None:
            try:
                from app.vpn_manager import vpn_manager_factory
                _vpn_manager = vpn_manager_factory(interactive=False)
                logger.info("‚úì VPN Manager iniciado (singleton)")
            except Exception as e:
                logger.error(f"‚úó Error iniciando VPN Manager: {e}")
                _vpn_manager = None
    return _vpn_manager


def rotate_vpn_now() -> Dict:
    """
    Rota la VPN inmediatamente.
    Llamado desde el endpoint /vpn/rotate de main.py
    """
    vpn = _get_vpn_manager()
    if not vpn:
        return {"success": False, "reason": "VPN_ENABLED=False o VPN no disponible"}

    with _vpn_lock:
        try:
            logger.info("üîÑ Rotaci√≥n VPN manual solicitada...")
            success = vpn.rotate()
            with _stats_lock:
                _stats["consecutive_failures"] = 0
                _stats["hotels_since_vpn_rotate"] = 0
            return {
                "success": success,
                "new_ip": vpn.current_ip,
                "server": vpn.current_server,
            }
        except Exception as e:
            logger.error(f"‚úó Error rotando VPN: {e}")
            return {"success": False, "error": str(e)}


def get_vpn_status() -> Dict:
    """Estado de la VPN. Llamado desde /vpn/status en main.py."""
    vpn = _get_vpn_manager()
    if not vpn:
        return {
            "enabled": False,
            "reason": "VPN_ENABLED=False en .env",
        }
    try:
        return {
            "enabled": True,
            **vpn.get_status(),
            "hotels_since_rotate": _stats.get("hotels_since_vpn_rotate", 0),
            "consecutive_failures": _stats.get("consecutive_failures", 0),
        }
    except Exception as e:
        return {"enabled": True, "error": str(e)}


def _maybe_rotate_vpn(force: bool = False):
    """
    Rota la VPN si:
    - force=True (llamada expl√≠cita)
    - Se super√≥ el l√≠mite de hoteles por servidor (VPN_ROTATE_EVERY_N default=10)
    - Hay 3+ fallos consecutivos (posible bloqueo IP)
    Thread-safe ‚Äî usa _vpn_lock para evitar rotaciones simult√°neas.
    """
    vpn = _get_vpn_manager()
    if not vpn:
        return

    with _stats_lock:
        consec = _stats["consecutive_failures"]
        since_rotate = _stats["hotels_since_vpn_rotate"]

    rotate_every = getattr(settings, "VPN_ROTATE_EVERY_N", 10)
    too_many_failures = consec >= 3

    if not (force or since_rotate >= rotate_every or too_many_failures):
        return

    reason = "manual" if force else ("bloqueo_ip" if too_many_failures else "periodica")
    logger.info(f"üîÑ Rotando VPN (motivo={reason}, fallos_consec={consec}, hoteles={since_rotate})...")

    with _vpn_lock:
        try:
            success = vpn.rotate()
            if success:
                with _stats_lock:
                    _stats["consecutive_failures"] = 0
                    _stats["hotels_since_vpn_rotate"] = 0
                logger.success(f"‚úì VPN rotada ‚Üí IP: {vpn.current_ip}")
            else:
                logger.warning("‚ö†Ô∏è Rotaci√≥n VPN fall√≥ ‚Äî continuando con IP actual")
        except Exception as e:
            logger.error(f"‚úó Error en rotaci√≥n VPN: {e}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PUNTO DE ENTRADA: PROCESAR BATCH
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def process_batch(batch_size: int = 5) -> Dict:
    """
    Obtiene URLs pendientes de la BD y las env√≠a al thread pool.
    Thread-safe. Puede llamarse desde asyncio (via run_in_executor).
    """
    # [FIX v3.0] VPN al iniciar el primer batch: conectar a US preferentemente.
    # Esto garantiza que el primer idioma (en) obtenga una IP angl√≥fona y Booking.com
    # sirva contenido en ingl√©s americano (no espa√±ol por IP espa√±ola).
    vpn = _get_vpn_manager()
    if vpn and settings.VPN_ENABLED:
        try:
            if not vpn.verify_vpn_active():
                logger.warning("‚ö†Ô∏è VPN inactiva al procesar batch ‚Äî conectando a US...")
                # Preferir US para scraping en ingl√©s; si falla, connect() elige aleatorio
                success = vpn.connect("US")
                if not success:
                    logger.warning("‚ö†Ô∏è Conexi√≥n a US fall√≥ ‚Äî intentando cualquier pa√≠s...")
                    vpn.connect()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error verificando VPN: {e}")

    db = SessionLocal()
    try:
        rows = db.execute(
            text("""
                SELECT id FROM url_queue
                WHERE  status = 'pending'
                  AND  retry_count < max_retries
                ORDER BY priority DESC, created_at ASC
                LIMIT  :limit
            """),
            {"limit": batch_size}
        ).fetchall()

        url_ids = [r[0] for r in rows]

        if not url_ids:
            logger.debug("‚ÑπÔ∏è No hay URLs pendientes para despachar")
            return {"dispatched": 0, "message": "No hay URLs pendientes"}

        # Filtrar IDs ya en proceso
        with _lock:
            new_ids = [uid for uid in url_ids if uid not in _active_ids]
            _active_ids.update(new_ids)

        if not new_ids:
            return {"dispatched": 0, "message": "Todas las URLs ya est√°n en proceso"}

        # Marcar como 'processing' en BD
        for uid in new_ids:
            db.execute(
                text("""
                    UPDATE url_queue
                    SET status = 'processing', updated_at = NOW()
                    WHERE id = :id
                """),
                {"id": uid}
            )
        db.commit()

        # Enviar al pool de threads
        for uid in new_ids:
            _executor.submit(_run_safe, uid)

        with _stats_lock:
            _stats["total_dispatched"] += len(new_ids)
            _stats["currently_processing"] += len(new_ids)

        logger.info(f"üöÄ Despachadas {len(new_ids)} URLs al thread pool")
        return {"dispatched": len(new_ids), "url_ids": new_ids}

    except Exception as e:
        logger.error(f"Error en process_batch: {e}")
        return {"dispatched": 0, "error": str(e)}
    finally:
        db.close()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SCRAPING DE UN HOTEL INDIVIDUAL
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _run_safe(url_id: int):
    """Wrapper que libera el ID del set _active_ids al terminar."""
    try:
        scrape_one(url_id)
    except Exception as e:
        logger.error(f"Error inesperado en _run_safe({url_id}): {e}")
    finally:
        with _lock:
            _active_ids.discard(url_id)
        with _stats_lock:
            _stats["currently_processing"] = max(0, _stats["currently_processing"] - 1)


def scrape_one(url_id: int) -> Dict:
    """
    Scrapea un hotel completo en todos los idiomas habilitados.

    CAMBIOS v2.1:
    - Con Selenium: crea UN SOLO driver por hotel (no uno por idioma)
    - Con cloudscraper: reinicia sesi√≥n si hay bloqueo repetido
    - Registra fallos consecutivos para disparar rotaci√≥n VPN
    """
    db = SessionLocal()
    start_time = time.time()

    try:
        row = db.execute(
            text("SELECT url, language FROM url_queue WHERE id = :id"),
            {"id": url_id}
        ).fetchone()

        if not row:
            logger.error(f"URL ID {url_id} no encontrada en url_queue")
            return {"error": "URL no encontrada"}

        base_url   = row[0]
        # [FIX BUG #2] queue_lang es el idioma de la URL almacenada. Se usa para
        # logging y trazabilidad. La normalizaci√≥n real ocurre en build_language_url()
        # que ahora elimina el sufijo existente antes de a√±adir el nuevo (ver BUG #1).
        queue_lang = row[1] or "en"
        logger.info(f"\n{'‚îÄ'*60}")
        logger.info(f"üè® Iniciando scraping | ID={url_id} | lang_queue={queue_lang} | {base_url}")
        logger.info(f"{'‚îÄ'*60}")

        # ‚îÄ‚îÄ Verificar VPN antes de este hotel ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        vpn = _get_vpn_manager()
        if vpn and settings.VPN_ENABLED:
            try:
                # [FIX v2.3] Proteger con _vpn_lock: evita que m√∫ltiples threads
                # llamen reconnect simult√°neamente ‚Üí m√∫ltiples connect() simult√°neos
                # ‚Üí NordVPN CLI colapsaba ‚Üí DNS inestable ‚Üí ERR_NAME_NOT_RESOLVED
                with _vpn_lock:
                    vpn.reconnect_if_disconnected()
            except Exception as vpn_err:
                logger.warning(f"‚ö†Ô∏è VPN check error: {vpn_err}")

        from app.scraper import BookingScraper, build_language_url

        languages = settings.ENABLED_LANGUAGES
        scraped_count = 0
        hotel_name = None
        lang_failures = 0

        # [FIX v2.4] Ingles SIEMPRE primero, sin excepcion.
        # Garantiza: (a) imagenes descargadas con sesion/cookies de la URL base (.html),
        # (b) independiente del orden en LANGUAGES_ENABLED del .env.
        # Si 'en' no esta en la lista, se inserta al inicio automaticamente.
        DEFAULT = settings.DEFAULT_LANGUAGE  # "en"
        if DEFAULT in languages:
            # Mover 'en' al frente si no esta ya
            languages = [DEFAULT] + [l for l in languages if l != DEFAULT]
        else:
            # 'en' no configurado ‚Üí insertar al inicio para garantizar descarga de imagenes
            logger.warning(
                f"  ‚ö†Ô∏è '{DEFAULT}' no esta en LANGUAGES_ENABLED. "
                f"Se inserta al inicio para descarga de imagenes."
            )
            languages = [DEFAULT] + languages

        # [v3.1] Flag: im√°genes descargadas del PRIMER idioma exitoso.
        # [v4.0] Cambiado: solo se descargan cuando lang='en' Y idioma confirmado correcto.
        images_downloaded = False

        # [v4.0] Contador de reintentos por mismatch de idioma (solo para lang='en')
        lang_retry_count = 0

        # ‚îÄ‚îÄ [FIX] Con Selenium: crear driver UNA sola vez por hotel ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        # Esto evita abrir/cerrar Brave 18 veces por hotel
        if settings.USE_SELENIUM:
            scraper_instance = BookingScraper()
            scraper_context = scraper_instance  # ya es una instancia, no context manager
        else:
            scraper_instance = None

        try:
            for lang in languages:
                lang_url = build_language_url(base_url, lang)
                logger.info(f"  ‚Üí [{url_id}] Idioma [{lang}]: {lang_url}")

                try:
                    if settings.USE_SELENIUM:
                        # Reusar el driver ya abierto
                        data = scraper_instance.scrape_hotel(lang_url, language=lang)
                    else:
                        # cloudscraper: usar context manager (gestiona sesi√≥n)
                        with BookingScraper() as scraper:
                            data = scraper.scrape_hotel(lang_url, language=lang)

                    if not data or not data.get("name"):
                        logger.warning(f"  ‚ö†Ô∏è [{url_id}][{lang}] Sin datos")
                        _log(db, url_id, lang, "no_data",
                             time.time() - start_time, 0, "Sin datos extra√≠dos")
                        lang_failures += 1
                        continue

                    if hotel_name is None:
                        hotel_name = data["name"]

                    # [v4.0 FIX #20] Verificar idioma ANTES de guardar.
                    # ANTES v3.1: mismatch ‚Üí warning + guardar igualmente (¬°INCORRECTO!)
                    # AHORA v4.0: mismatch ‚Üí NO guardar + log 'lang_mismatch'
                    detected = data.get("detected_lang")
                    if detected and detected != lang:
                        logger.error(
                            f"  üö´ [{url_id}][{lang}] IDIOMA INCORRECTO ‚Äî NO SE GUARDA: "
                            f"solicitado='{lang}', p√°gina en '{detected}' "
                            f"(GeoIP/VPN devuelve sesi√≥n en idioma incorrecto)"
                        )
                        with _stats_lock:
                            _stats["lang_mismatch_count"] = _stats.get("lang_mismatch_count", 0) + 1
                            _stats["lang_mismatch_blocked"] = _stats.get("lang_mismatch_blocked", 0) + 1

                        # Loguear en BD como mismatch (no como 'completed')
                        _log(db, url_id, lang, "lang_mismatch",
                             time.time() - start_time, 0,
                             f"P√°gina en '{detected}', solicitado '{lang}'. Dato NO guardado.")

                        # [v4.0 FIX #22] Retry solo para ingl√©s (idioma principal)
                        # Los otros idiomas no se reintentan (menos cr√≠ticos)
                        if lang == DEFAULT and lang_retry_count < _MAX_LANG_RETRY:
                            lang_retry_count += 1
                            logger.warning(
                                f"  üîÑ [{url_id}][{lang}] Reintento {lang_retry_count}/{_MAX_LANG_RETRY} "
                                f"(mismatch de idioma ‚Üí nueva sesi√≥n)..."
                            )
                            # Peque√±a pausa antes de reintentar
                            time.sleep(3)
                            # Forzar nueva sesi√≥n CloudScraper descartando la actual
                            if hasattr(scraper_instance, '_session'):
                                try:
                                    scraper_instance._session = None
                                except Exception:
                                    pass
                            continue  # ‚Üê Reintentar el mismo lang

                        # Sin m√°s reintentos ‚Üí rotar VPN si hay 3+ mismatches
                        if _stats.get("lang_mismatch_count", 0) >= 3:
                            logger.warning(
                                f"  üîÑ [{url_id}] {_stats['lang_mismatch_count']} mismatches "
                                f"de idioma consecutivos ‚Üí rotando VPN..."
                            )
                            _maybe_rotate_vpn(force=True)
                            with _stats_lock:
                                _stats["lang_mismatch_count"] = 0

                        lang_failures += 1
                        lang_retry_count = 0  # reset para pr√≥ximo idioma
                        continue  # ‚Üê SKIP SAVE ‚Äî no guardar dato en idioma incorrecto
                    else:
                        # Idioma correcto ‚Üí reset contadores
                        with _stats_lock:
                            _stats["lang_mismatch_count"] = 0
                        lang_retry_count = 0

                    # Guardar en BD
                    _save_hotel(db, url_id, lang_url, lang, data)
                    scraped_count += 1
                    lang_failures = 0  # reset fallos consecutivos por idioma

                    imgs_count = len(data.get("images_urls") or [])
                    duration = time.time() - start_time
                    # items_extracted = 1 por registro guardado (no numero de imagenes)
                    _log(db, url_id, lang, "completed", duration, 1)

                    logger.success(
                        f"  ‚úì [{url_id}][{lang}] '{hotel_name}' "
                        f"| rating={data.get('rating')} "
                        f"| imgs={imgs_count}"
                    )

                    # ‚îÄ‚îÄ Descarga de im√°genes ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                    # [v4.0 FIX #21] Solo descargar im√°genes cuando:
                    #   1. lang == DEFAULT ('en')  ‚Äî idioma principal
                    #   2. detected_lang == 'en'   ‚Äî p√°gina confirmada en ingl√©s
                    #   3. A√∫n no se han descargado para este hotel
                    # ANTES v3.1: "primer idioma exitoso" (pod√≠a ser ES con contenido ES)
                    # AHORA v4.0: solo ingl√©s confirmado ‚Üí carpeta destino SIEMPRE 'en'
                    if lang == DEFAULT and not images_downloaded and settings.DOWNLOAD_IMAGES:
                        imgs = data.get("images_urls") or []
                        if imgs:
                            driver = scraper_instance.driver if settings.USE_SELENIUM else None
                            # Hardcodear lang='en' como carpeta destino (regla: siempre en/)
                            n_downloaded = _download_images(url_id, imgs, DEFAULT, driver=driver)
                            if n_downloaded and n_downloaded > 0:
                                try:
                                    db.execute(
                                        text("""
                                            UPDATE hotels
                                            SET images_count = :count, updated_at = NOW()
                                            WHERE url_id = :url_id AND language = :lang
                                        """),
                                        {"count": n_downloaded, "url_id": url_id, "lang": DEFAULT}
                                    )
                                    db.commit()
                                    logger.debug(
                                        f"  üì∑ [{url_id}] images_count={n_downloaded} "
                                        f"actualizado en BD (lang='{DEFAULT}', carpeta=en/)"
                                    )
                                except Exception as upd_err:
                                    logger.debug(f"  ‚ö†Ô∏è No se pudo actualizar images_count: {upd_err}")
                        images_downloaded = True
                        logger.debug(f"  üì∑ [{url_id}] Im√°genes descargadas y marcadas (lang='{DEFAULT}')")

                except Exception as lang_err:
                    err_str = str(lang_err)
                    logger.error(f"  ‚úó [{url_id}][{lang}] {err_str[:200]}")
                    try:
                        db.rollback()
                    except Exception:
                        pass

                    # [FIX v2.3] Session Selenium muerta (browser crasheo) ‚Üí recrear driver y reintentar
                    if settings.USE_SELENIUM and "invalid session id" in err_str.lower():
                        logger.warning(f"  ‚ö†Ô∏è [{url_id}][{lang}] Brave crasheo ‚Äî recreando driver y reintentando...")
                        try:
                            scraper_instance.close()
                        except Exception:
                            pass
                        try:
                            scraper_instance = BookingScraper()
                            data = scraper_instance.scrape_hotel(lang_url, language=lang)
                            if data and data.get("name"):
                                if hotel_name is None:
                                    hotel_name = data["name"]
                                _save_hotel(db, url_id, lang_url, lang, data)
                                scraped_count += 1
                                lang_failures = 0
                                duration = time.time() - start_time
                                _log(db, url_id, lang, "completed", duration,
                                     len(data.get("images_urls") or []))
                                logger.success(
                                    f"  ‚úì [{url_id}][{lang}] '{hotel_name}' (recuperado) "
                                    f"| rating={data.get('rating')}"
                                )
                                # [FIX v3.1] Recovery: descargar im√°genes del primer idioma exitoso
                                # (igual que el flujo normal, sin restricci√≥n a lang == DEFAULT)
                                if not images_downloaded and settings.DOWNLOAD_IMAGES:
                                    imgs = data.get("images_urls") or []
                                    if imgs:
                                        driver = scraper_instance.driver if settings.USE_SELENIUM else None
                                        n_downloaded = _download_images(url_id, imgs, lang, driver=driver)
                                        if n_downloaded and n_downloaded > 0:
                                            try:
                                                db.execute(
                                                    text("UPDATE hotels SET images_count = :c, updated_at = NOW() WHERE url_id = :u"),
                                                    {"c": n_downloaded, "u": url_id}
                                                )
                                                db.commit()
                                            except Exception:
                                                pass
                                    images_downloaded = True
                                continue  # siguiente idioma con exito
                        except Exception as retry_err:
                            logger.error(f"  ‚úó [{url_id}][{lang}] Reintento fallido: {retry_err}")
                            try:
                                db.rollback()
                            except Exception:
                                pass

                    _log(db, url_id, lang, "error",
                         time.time() - start_time, 0, err_str[:500])
                    lang_failures += 1

                    if lang_failures >= 3:
                        logger.warning(f"  ‚ö†Ô∏è [{url_id}] {lang_failures} fallos seguidos ‚Äî posible bloqueo IP")
                        with _stats_lock:
                            _stats["consecutive_failures"] += 1
                        _maybe_rotate_vpn()

        finally:
            # Cerrar el driver Selenium al terminar TODOS los idiomas del hotel
            if settings.USE_SELENIUM and scraper_instance is not None:
                try:
                    scraper_instance.close()
                    logger.debug(f"  ‚úì Driver Selenium cerrado para hotel {url_id}")
                except Exception:
                    pass

        # ‚îÄ‚îÄ Actualizar estado final ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        final_status = "completed" if scraped_count > 0 else "failed"
        db.execute(
            text("""
                UPDATE url_queue
                SET status = :status, scraped_at = NOW(), updated_at = NOW()
                WHERE id = :id
            """),
            {"status": final_status, "id": url_id}
        )
        db.commit()

        total_dur = time.time() - start_time

        if scraped_count > 0:
            with _stats_lock:
                _stats["total_completed"] += 1
                _stats["consecutive_failures"] = 0  # √©xito ‚Üí reset fallos
                _stats["hotels_since_vpn_rotate"] += 1

            # ¬øEs momento de rotar la VPN peri√≥dicamente?
            _maybe_rotate_vpn()

            logger.success(
                f"‚úÖ [{url_id}] COMPLETADO | '{hotel_name}' "
                f"| {scraped_count}/{len(languages)} idiomas "
                f"| {total_dur:.1f}s"
            )
        else:
            with _stats_lock:
                _stats["total_failed"] += 1
                _stats["consecutive_failures"] += 1
            _maybe_rotate_vpn()  # fallo total ‚Üí intentar rotar
            logger.error(f"‚úó [{url_id}] FALLIDO | {total_dur:.1f}s")

        return {
            "success":    scraped_count > 0,
            "hotel_name": hotel_name,
            "languages":  scraped_count,
            "duration":   round(total_dur, 2),
        }

    except Exception as e:
        logger.error(f"‚ùå Error fatal URL {url_id}: {e}", exc_info=True)
        db.rollback()
        with _stats_lock:
            _stats["total_failed"] += 1
            _stats["consecutive_failures"] += 1
        _maybe_rotate_vpn()
        try:
            db.execute(
                text("""
                    UPDATE url_queue
                    SET status = CASE
                            WHEN retry_count + 1 >= max_retries THEN 'failed'
                            ELSE 'pending'
                        END,
                        retry_count = retry_count + 1,
                        last_error  = :error,
                        updated_at  = NOW()
                    WHERE id = :id
                """),
                {"id": url_id, "error": str(e)[:500]}
            )
            db.commit()
        except Exception:
            pass
        return {"error": str(e)}

    finally:
        db.close()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# HELPERS INTERNOS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _save_hotel(db, url_id: int, url: str, lang: str, data: Dict):
    """Inserta o actualiza un hotel en la BD."""
    db.execute(
        text("""
            INSERT INTO hotels (
                url_id, url, language,
                name, address, description,
                rating, total_reviews, rating_category,
                review_scores, services, facilities,
                house_rules, important_info,
                rooms_info, images_urls,
                scraped_at, updated_at
            ) VALUES (
                :url_id, :url, :language,
                :name, :address, :description,
                :rating, :total_reviews, :rating_category,
                CAST(:review_scores AS jsonb), CAST(:services AS jsonb), CAST(:facilities AS jsonb),
                :house_rules, :important_info,
                CAST(:rooms_info AS jsonb), CAST(:images_urls AS jsonb),
                NOW(), NOW()
            )
            ON CONFLICT (url_id, language) DO UPDATE SET
                name            = EXCLUDED.name,
                address         = EXCLUDED.address,
                description     = EXCLUDED.description,
                rating          = EXCLUDED.rating,
                total_reviews   = EXCLUDED.total_reviews,
                rating_category = EXCLUDED.rating_category,
                review_scores   = EXCLUDED.review_scores,
                services        = EXCLUDED.services,
                facilities      = EXCLUDED.facilities,
                house_rules     = EXCLUDED.house_rules,
                important_info  = EXCLUDED.important_info,
                rooms_info      = EXCLUDED.rooms_info,
                images_urls     = EXCLUDED.images_urls,
                updated_at      = NOW()
        """),
        {
            "url_id":           url_id,
            "url":              url,
            "language":         lang,
            "name":             data.get("name"),
            "address":          data.get("address"),
            "description":      data.get("description"),
            "rating":           data.get("rating"),
            "total_reviews":    data.get("total_reviews"),
            "rating_category":  data.get("rating_category"),
            "review_scores":    json.dumps(data.get("review_scores") or {}),
            "services":         json.dumps(data.get("services")      or []),
            "facilities":       json.dumps(data.get("facilities")    or {}),
            "house_rules":      data.get("house_rules"),
            "important_info":   data.get("important_info"),
            "rooms_info":       json.dumps(data.get("rooms")         or []),
            "images_urls":      json.dumps(data.get("images_urls")   or []),
        }
    )
    db.commit()


def _download_images(url_id: int, img_urls: List[str], lang: str, driver=None) -> int:
    """
    Descarga imagenes usando la sesion del browser Brave (cookies validas).
    [FIX v2.4] Booking.com CDN (bstatic.com) bloquea requests directos.
    Al pasar el driver Selenium, se extraen sus cookies y referer para
    que la descarga sea autenticada como una peticion normal del browser.
    [FIX v3.1] Retorna el n√∫mero de im√°genes descargadas exitosamente
    para actualizar images_count en BD.
    """
    if not img_urls:
        return 0

    try:
        from app.image_downloader import ImageDownloader
        import requests as _req

        # Construir sesion autenticada con cookies del browser Brave
        session = _req.Session()
        session.headers.update({
            "User-Agent":      "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                               "AppleWebKit/537.36 (KHTML, like Gecko) "
                               "Chrome/124.0.0.0 Safari/537.36",
            "Referer":         "https://www.booking.com/",
            "Accept":          "image/avif,image/webp,image/apng,image/*,*/*;q=0.8",
            "Accept-Language": "en-US,en;q=0.9,*;q=0.5",
            "sec-fetch-dest":  "image",
            "sec-fetch-mode":  "no-cors",
            "sec-fetch-site":  "cross-site",
        })

        # Extraer cookies del driver Brave (si est√° disponible)
        if driver:
            try:
                browser_cookies = driver.get_cookies()
                for c in browser_cookies:
                    session.cookies.set(
                        c["name"], c["value"],
                        domain=c.get("domain", ".booking.com"),
                    )
                logger.debug(f"  üì∑ [{url_id}] {len(browser_cookies)} cookies extra√≠das del browser")
            except Exception as ce:
                logger.debug(f"  üì∑ [{url_id}] No se pudieron extraer cookies: {ce}")

        dl = ImageDownloader()
        results = dl.download_images(url_id, img_urls, language=lang, session=session)
        ok = len(results)
        logger.info(f"  üì∑ [{url_id}] {ok}/{len(img_urls)} im√°genes descargadas")
        return ok

    except Exception as e:
        logger.warning(f"  ‚ö†Ô∏è Error descargando im√°genes [{url_id}]: {e}")
        return 0


def _log(db, url_id: int, language: str, status: str,
         duration: float, items: int, error: str = None):
    """Inserta una l√≠nea en scraping_logs."""
    try:
        db.execute(
            text("""
                INSERT INTO scraping_logs
                    (url_id, language, status, duration_seconds,
                     items_extracted, error_message, timestamp)
                VALUES
                    (:url_id, :lang, :status, :dur,
                     :items, :error, NOW())
            """),
            {
                "url_id": url_id,
                "lang":   language,
                "status": status,
                "dur":    round(duration, 2),
                "items":  items,
                "error":  error,
            }
        )
        db.commit()
    except Exception as e:
        logger.debug(f"No se pudo insertar log: {e}")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ESTADO DEL SERVICIO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def get_service_stats() -> Dict:
    """Devuelve estad√≠sticas en tiempo real del servicio de scraping."""
    with _lock:
        active = list(_active_ids)
    with _stats_lock:
        s = _stats.copy()
    s["active_ids"] = active
    s["active_count"] = len(active)
    return s
